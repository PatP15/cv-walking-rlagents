{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing on small amount of data first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tNLZ8w6G86Ye"
      },
      "outputs": [],
      "source": [
        "# Sets the path to the terrain data directory\n",
        "DATA_DIR = r'C:\\Users\\User\\OneDrive\\Documents\\GitHub\\cv-walking-rlagents\\Assets\\Snapshots\\terrain_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\OneDrive\\Documents\\GitHub\\image-classification-yolov8\n"
          ]
        }
      ],
      "source": [
        "# This was for setting up the environment required for training the model\n",
        "# %cd \"C:\\Users\\User\\OneDrive\\Documents\\GitHub\\image-classification-yolov8\"\n",
        "# %pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zy7BcAyj9LvW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-cls.pt to yolov8n-cls.pt...\n",
            "100%|██████████| 5.28M/5.28M [00:01<00:00, 4.04MB/s]\n",
            "New https://pypi.org/project/ultralytics/8.0.221 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.0.58  Python-3.11.6 torch-2.1.1+cpu CPU\n",
            "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:\\Users\\User\\OneDrive\\Documents\\GitHub\\cv-walking-rlagents\\Assets\\Snapshots\\terrain_data, epochs=10, patience=50, batch=16, imgsz=64, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\classify\\train\n",
            "Overriding model.yaml nc=1000 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
            "  9                  -1  1    334083  ultralytics.nn.modules.Classify              [256, 3]                      \n",
            "YOLOv8n-cls summary: 99 layers, 1442131 parameters, 1442131 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias\n",
            "Image sizes 64 train, 64 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns\\classify\\train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       1/10         0G     0.2384         10         64: 100%|██████████| 59/59 [00:12<00:00,  4.67it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
            "                   all      0.407          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       2/10         0G     0.2137         10         64: 100%|██████████| 59/59 [00:11<00:00,  5.11it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n",
            "                   all      0.407          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       3/10         0G     0.1503         10         64: 100%|██████████| 59/59 [00:11<00:00,  5.16it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n",
            "                   all      0.481          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       4/10         0G     0.1091         10         64: 100%|██████████| 59/59 [00:11<00:00,  5.34it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n",
            "                   all      0.296          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       5/10         0G    0.07318         10         64: 100%|██████████| 59/59 [00:11<00:00,  5.20it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s]\n",
            "                   all      0.704          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       6/10         0G    0.03863         10         64: 100%|██████████| 59/59 [00:11<00:00,  5.09it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
            "                   all      0.593          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       7/10         0G    0.02415         10         64: 100%|██████████| 59/59 [00:11<00:00,  5.03it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s]\n",
            "                   all      0.852          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       8/10         0G    0.01718         10         64: 100%|██████████| 59/59 [00:12<00:00,  4.79it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s]\n",
            "                   all      0.852          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       9/10         0G   0.009604         10         64: 100%|██████████| 59/59 [00:12<00:00,  4.80it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      10/10         0G   0.005654         10         64: 100%|██████████| 59/59 [00:13<00:00,  4.37it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s]\n",
            "                   all      0.815          1\n",
            "\n",
            "10 epochs completed in 0.034 hours.\n",
            "Optimizer stripped from runs\\classify\\train\\weights\\last.pt, 3.0MB\n",
            "Optimizer stripped from runs\\classify\\train\\weights\\best.pt, 3.0MB\n",
            "Results saved to \u001b[1mruns\\classify\\train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8n-cls.pt\")  # load a pretained model\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data=DATA_DIR, epochs=10, imgsz=64)  # train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# now set the new model path to the best model \n",
        "model_path = r'C:\\Users\\User\\OneDrive\\Documents\\GitHub\\cv-walking-rlagents\\ModelTraining\\runs\\detect\\terrain_train\\runs\\classify\\train\\weights\\best.pt'\n",
        "# create a separate variable for the path to the test data set \n",
        "test_data_path = r'C:\\Users\\User\\OneDrive\\Documents\\GitHub\\cv-walking-rlagents\\Assets\\Snapshots\\terrain_test_spec'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.58  Python-3.11.6 torch-2.1.1+cpu CPU\n",
            "YOLOv8n-cls summary (fused): 73 layers, 1438723 parameters, 0 gradients, 3.3 GFLOPs\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 2/2 [00:00<00:00,  6.61it/s]\n",
            "                   all      0.926          1\n",
            "Speed: 0.0ms preprocess, 2.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns\\classify\\val2\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ultralytics.yolo.utils.metrics.ClassifyMetrics object with attributes:\n",
              "\n",
              "fitness: 1.0\n",
              "keys: ['metrics/accuracy_top1', 'metrics/accuracy_top5']\n",
              "results_dict: {'metrics/accuracy_top1': 0.9259259104728699, 'metrics/accuracy_top5': 1.0, 'fitness': 1.0}\n",
              "speed: {'preprocess': 0.0, 'inference': 2.793320903071651, 'loss': 0.0, 'postprocess': 0.0}\n",
              "top1: 0.9259259104728699\n",
              "top5: 1.0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run val on the test data :) to get the accuracy of the model (once you've swapped in the folder whe)\n",
        "test_model = YOLO(model_path)   \n",
        "\n",
        "test_model.val(test_data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test on Larger amount of data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Delete .meta files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Remove all .meta files from a directory\n",
        "def remove_meta_files(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        print(f\"The directory {directory} does not exist.\")\n",
        "        return\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.meta'):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            os.remove(file_path)\n",
        "            print(f\"Removed {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "directory_path = r'C:\\Users\\User\\OneDrive\\Documents\\GitHub\\cv-walking-rlagents\\Assets\\Snapshots\\2'\n",
        "remove_meta_files(directory_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split Data\n",
        "\n",
        "Set as 80% training, 10% validation, 10% test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data splitting completed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def split_data(source_dir, train_dir, val_dir, test_dir, split_ratio=(0.8, 0.1, 0.1)):\n",
        "    # Ensure the source directory exists\n",
        "    if not os.path.isdir(source_dir):\n",
        "        print(f\"Source directory {source_dir} does not exist.\")\n",
        "        return\n",
        "\n",
        "    # Create the destination directories if they don't exist\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "    # Get all files in the source directory\n",
        "    all_files = os.listdir(source_dir)\n",
        "    random.shuffle(all_files)  # Shuffle to randomize selection\n",
        "\n",
        "    # Calculate split indices\n",
        "    total_files = len(all_files)\n",
        "    train_end = int(total_files * split_ratio[0])\n",
        "    val_end = train_end + int(total_files * split_ratio[1])\n",
        "\n",
        "    # Split files into train, val, and test\n",
        "    train_files = all_files[:train_end]\n",
        "    val_files = all_files[train_end:val_end]\n",
        "    test_files = all_files[val_end:]\n",
        "\n",
        "    # Function to copy files to a target directory\n",
        "    def copy_files(files, target_dir):\n",
        "        os.makedirs(target_dir, exist_ok=True)\n",
        "        for file in files:\n",
        "            shutil.copy(os.path.join(source_dir, file), os.path.join(target_dir, file))\n",
        "\n",
        "    # Copy files to respective directories\n",
        "    copy_files(train_files, os.path.join(train_dir, os.path.basename(source_dir)))\n",
        "    copy_files(val_files, os.path.join(val_dir, os.path.basename(source_dir)))\n",
        "    copy_files(test_files, os.path.join(test_dir, os.path.basename(source_dir)))\n",
        "\n",
        "# Directories\n",
        "base_dir = r'C:\\Users\\User\\OneDrive\\Documents\\GitHub\\cv-walking-rlagents\\Assets\\Snapshots'  \n",
        "directories = ['0', '1', '2']\n",
        "\n",
        "for dir in directories:\n",
        "    split_data(os.path.join(base_dir, dir), \n",
        "               os.path.join(base_dir, 'train'), \n",
        "               os.path.join(base_dir, 'val'), \n",
        "               os.path.join(base_dir, 'test'))\n",
        "\n",
        "print(\"Data splitting completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training with Lots of Terrain Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sets the path to the terrain data directory\n",
        "data_directory = r'C:\\Users\\User\\OneDrive\\Documents\\GitHub\\cv-walking-rlagents\\Assets\\Snapshots\\terrain_data'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
