{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tNLZ8w6G86Ye"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = r'C:\\Users\\User\\OneDrive\\Documents\\GitHub\\cv-walking-rlagents\\Assets\\Snapshots\\terrain_data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\User\\OneDrive\\Documents\\GitHub\\image-classification-yolov8\n"
          ]
        }
      ],
      "source": [
        "%cd \"C:\\Users\\User\\OneDrive\\Documents\\GitHub\\image-classification-yolov8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zy7BcAyj9LvW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-cls.pt to yolov8n-cls.pt...\n",
            "100%|██████████| 5.28M/5.28M [00:01<00:00, 4.04MB/s]\n",
            "New https://pypi.org/project/ultralytics/8.0.221 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics YOLOv8.0.58  Python-3.11.6 torch-2.1.1+cpu CPU\n",
            "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=C:\\Users\\User\\OneDrive\\Documents\\GitHub\\cv-walking-rlagents\\Assets\\Snapshots\\terrain_data, epochs=10, patience=50, batch=16, imgsz=64, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\classify\\train\n",
            "Overriding model.yaml nc=1000 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
            "  9                  -1  1    334083  ultralytics.nn.modules.Classify              [256, 3]                      \n",
            "YOLOv8n-cls summary: 99 layers, 1442131 parameters, 1442131 gradients, 3.4 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias\n",
            "Image sizes 64 train, 64 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns\\classify\\train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       1/10         0G     0.2384         10         64: 100%|██████████| 59/59 [00:12<00:00,  4.67it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
            "                   all      0.407          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       2/10         0G     0.2137         10         64: 100%|██████████| 59/59 [00:11<00:00,  5.11it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n",
            "                   all      0.407          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       3/10         0G     0.1503         10         64: 100%|██████████| 59/59 [00:11<00:00,  5.16it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n",
            "                   all      0.481          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       4/10         0G     0.1091         10         64: 100%|██████████| 59/59 [00:11<00:00,  5.34it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.70it/s]\n",
            "                   all      0.296          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       5/10         0G    0.07318         10         64: 100%|██████████| 59/59 [00:11<00:00,  5.20it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s]\n",
            "                   all      0.704          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       6/10         0G    0.03863         10         64: 100%|██████████| 59/59 [00:11<00:00,  5.09it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.76it/s]\n",
            "                   all      0.593          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       7/10         0G    0.02415         10         64: 100%|██████████| 59/59 [00:11<00:00,  5.03it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s]\n",
            "                   all      0.852          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       8/10         0G    0.01718         10         64: 100%|██████████| 59/59 [00:12<00:00,  4.79it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.11it/s]\n",
            "                   all      0.852          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       9/10         0G   0.009604         10         64: 100%|██████████| 59/59 [00:12<00:00,  4.80it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s]\n",
            "                   all      0.926          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      10/10         0G   0.005654         10         64: 100%|██████████| 59/59 [00:13<00:00,  4.37it/s]\n",
            "               classes   top1_acc   top5_acc: 100%|██████████| 1/1 [00:00<00:00,  4.55it/s]\n",
            "                   all      0.815          1\n",
            "\n",
            "10 epochs completed in 0.034 hours.\n",
            "Optimizer stripped from runs\\classify\\train\\weights\\last.pt, 3.0MB\n",
            "Optimizer stripped from runs\\classify\\train\\weights\\best.pt, 3.0MB\n",
            "Results saved to \u001b[1mruns\\classify\\train\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8n-cls.pt\")  # load a pretained model\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data=DATA_DIR, epochs=10, imgsz=64)  # train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# metrics = model.val(os.path.join(DATA_DIR, 'test'))  # calculate metrics\n",
        "\n",
        "# print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from ultralytics import YOLO  # Make sure to install Ultralytics YOLO package\n",
        "# from torchvision import transforms\n",
        "# from torch.utils.data import DataLoader\n",
        "# import sys\n",
        "\n",
        "\n",
        "# def test_model_accuracy(model_path, test_data_path, batch_size=16, num_classes=80):\n",
        "#     # Load the trained model\n",
        "#     model = YOLO(model_path)\n",
        "\n",
        "#     # Prepare the test dataset\n",
        "#     transform = transforms.Compose([\n",
        "#         transforms.ToTensor(),\n",
        "#         # Add any other transformations you used during training\n",
        "#     ])\n",
        "#     test_dataset = CustomImageDataset(test_data_path, transform=transform)  # Replace with your dataset\n",
        "#     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "#     # Switch model to evaluation mode\n",
        "#     model.eval()\n",
        "\n",
        "#     # Variables to store performance metrics\n",
        "#     total, correct = 0, 0\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for images, labels in test_loader:\n",
        "#             outputs = model(images)\n",
        "#             # Calculate accuracy\n",
        "#             # Note: You need to modify this part based on how your labels and outputs are structured\n",
        "#             # This is a placeholder logic for accuracy calculation\n",
        "#             _, predicted = torch.max(outputs.data, 1)\n",
        "#             total += labels.size(0)\n",
        "#             correct += (predicted == labels).sum().item()\n",
        "\n",
        "#     accuracy = 100 * correct / total\n",
        "#     return accuracy\n",
        "\n",
        "# # Example usage\n",
        "# model_path = r'C:\\Users\\User\\OneDrive\\Documents\\GitHub\\cv-walking-rlagents\\ModelTraining\\runs\\detect\\terrain_train\\runs\\classify\\train\\weights\\best.pt'\n",
        "# test_data_path = r'C:\\Users\\User\\OneDrive\\Documents\\GitHub\\cv-walking-rlagents\\Assets\\Snapshots\\terrain_data\\test'\n",
        "# accuracy = test_model_accuracy(model_path, test_data_path)\n",
        "# print(f\"Model Accuracy: {accuracy}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test_model = YOLO(model_path) \n",
        "\n",
        "# test_model.predict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_model = YOLO(model_path)   \n",
        "\n",
        "test_model.val()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
